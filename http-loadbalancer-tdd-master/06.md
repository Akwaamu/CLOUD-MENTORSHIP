# Load Balancing Algorithms

Chapter six covers the implementation of a number of common load balancing algorithms that are used to maximize resiliency. We'll continue building on our current load balancer implementation by adding new ways of load balancing traffic.

## What is a Load Balancing Algorithm?

Load balancing algorithms are used to determine which backend server will be selected when load balancing.

For example, perhaps you have three backend servers in your server pool. Two are normal servers while one has much more memory and processing power. In this case, the "weighted" algorithm can be used to send more traffic to the more powerful server than the other two servers. This is just one of many algorithms that can be used.

In this chapter, you'll learn about six load balancing algorithms. You'll also implement two of them.

## Random Algorithm

This is the algorithm that we're currently using, which we implemented in chapter two:

```python
def get_healthy_server(host, register):
    try:
        return random.choice([server for server in register[host] if server.healthy])
    except IndexError:
        return None
```

Using the theory of probability, over a long period of time, traffic should be evenly distributed. However, there's no guarantee of that, especially when we don't have a determining factor.

## Least Connections Algorithm

The Least Connections algorithm sends traffic to the backend server that has the least number of open connections. This helps to make sure that servers are not sitting idle and connections are being spread across the servers. Let's implement a basic version of this.

Example pseudocode:

```python
# start with  a list of servers
servers = [backend1, backend2, backend3]

# method for obtaining the number of open connections
backend1.open_connections

# hence we can get something like this
server_connections = [0, 1, 10]

# out of the 3 backend servers, backend1 has the least connections
# so this can be the server that receives traffic
```

In chapter four we implemented a `Server` class in *models.py*. Let's add an `open_connections` attribute:

```python
...

class Server:
    def __init__(self, endpoint, path='/healthcheck'):
        self.endpoint = endpoint
        self.path = path
        self.healthy = True
        self.timeout = 1
        self.scheme = 'http://'
        self.open_connections = 0

...
```

Now we need to increment the counter whenever we open a connection to a backend server and decrement it whenever a connection is closed. To do so, update the `router` view function in *loadbalancer.py*:

```python
@loadbalancer.route('/')
@loadbalancer.route('/<path>')
def router(path='/'):
    updated_register = healthcheck(register)
    host_header = request.headers['Host']

    for entry in config['hosts']:
        if host_header == entry['host']:
            healthy_server = get_healthy_server(entry['host'], updated_register)
            if not healthy_server:
                return 'No backend servers available.', 503
            headers = process_rules(config, host_header, {k:v for k,v in request.headers.items()}, 'header')
            params = process_rules(config, host_header, {k:v for k,v in request.args.items()}, 'param')
            rewrite_path = ''
            if path == 'v1':
                rewrite_path = process_rewrite_rules(config, host_header, path)
            response = requests.get(f'http://{healthy_server.endpoint}/{rewrite_path}', headers=headers, params=params)
            return response.content, response.status_code

    for entry in config['paths']:
        if ('/' + path) == entry['path']:
            healthy_server = get_healthy_server(entry['path'], register)
            if not healthy_server:
                return 'No backend servers available.', 503
            healthy_server.open_connections += 1
            response = requests.get(f'http://{healthy_server.endpoint}')
            healthy_server.open_connections -= 1
            return response.content, response.status_code

    return 'Not Found', 404
```

So, we added to the counter just before we sent a request and subtracted from it after the request completes.

We currently run the `get_healthy_server` method to fetch at random a healthy server. Based on the pseudocode, we should replace that with a `least_connections` method.

Let's start off by adding some tests to *test_utils.py*:

```python
def test_least_connections_empty_list():
    result = least_connections([])
    assert result == None


def test_least_connections():
    backend1 = Server('localhost:8081')
    backend1.open_connections = 10
    backend2 = Server('localhost:8082')
    backend2.open_connections = 5
    backend3 = Server('localhost:8083')
    backend3.open_connections = 2
    servers = [backend1, backend2, backend3]
    result = least_connections(servers)
    assert result == backend3
```

We defined our servers and set the open connections for each one and then we asserted that the one with the least number of connections is returned.

Make sure these new tests fail.

Let's implement this.

Add the new function to *utils.py*:

```python
def least_connections(servers):
    if not servers:
        return None
    return min(servers, key=lambda x: x.open_connections)
```

Here, we used `min`, from the standard library, to return the server instance that has the minimum number of connections. Add the import to *test_utils.py*. With that our tests should pass:

```sh
$ docker build -t server .
(env)$ make test

==================================================== test session starts =====================================================
platform darwin -- Python 3.9.0, pytest-6.1.2, py-1.9.0, pluggy-0.13.1
rootdir: /Users/michael/repos/testdriven/http-load-balancer
collected 21 items

test_loadbalancer.py .........                                                                                         [ 42%]
test_models.py ....                                                                                                    [ 61%]
test_utils.py ........                                                                                                 [100%]

===================================================== 21 passed in 0.87s =====================================================
```

Now we need to tell our load balancer to use the `least_connections` function in the `get_healthy_server` function in *utils.py*:

```python
def get_healthy_server(host, register):
    try:
        return least_connections([server for server in register[host] if server.healthy])
    except IndexError:
        return None
```

In the above code, we changed our default load balancing behavior to use the least connections approach. Run the tests again to verify that we did not break anything in the process.

## Random Weighted Algorithm

Weighted algorithms can help to give a preference to certain servers over others as such we can attach weights to each of them. We won't implement this algorithm in this course, but if you want to try on your own, you'll probably want to add the weight to the configuration file.

For example:

```yaml
hosts:
  - host: www.mango.com
    servers:
      - endpoint: localhost:8081
        weight: 0.2
      - endpoint: localhost:8082
        weight: 0.2
      - endpoint: localhost:9081
        weight: 0.6
```

You could then modify the `get_healthy_server` function to respect these weights as follows:

```python
def get_healthy_server(host, register):
    healthy_servers = [server for server in register[host] if server.healthy]
    weights = [server.weight for server in healthy_servers]
    try:
        return random.choices(population=healthy_servers, weights=weights, k=1)[0]
    except IndexError:
        return None
```

So, after fetching the healthy servers along with their respective weights, you could then use `random.choices` to assign the weights and return back the weighted server.

## Round Robin Algorithm

Round Robin is another commonly used algorithm. Essentially, load is evenly balanced across servers guaranteeing that the traffic is spread evenly. Given three backend servers, round robin will cause the first request to go to the first server, the second request to the second server, the third to the third server, and the fourth to the first server, and so forth. This removes the randomness and always guarantees an even distribution.

## IP Source Hashing

IP Source Hashing is an algorithm that is used to send the client to the same backend server for consecutive requests. This is known as a sticky session or persistent connection.

For example, say a client establishes a long-running connection with a backend server but the connection is cut off for some reason. If the client reconnects, it might go to another server and that server will start a new session, which means that the client has lost state. To prevent this, the IP and other parts of the source are hashed and kept in memory and when a new request comes in, a lookup is done against the hash table and the request is sent to the same backend server.

## Global Server Load Balancing (GSLB)

GSLB is method of distributing web traffic across different geographic backend servers. This is less of an algorithm but more of a strategy where the load balancer routes the client request to the server closest to the client.

Perhaps a particular website has backend servers in both the US and Europe. If all client requests get sent to the servers in Europe, then the US clients will experience latency simply due to the geographic distance between the client and server. Instead, if we had a GSLB in front that routes traffic to the servers in US, the client experiences lower latency. A good example of this are Amazon S3 buckets, which have a global and regional endpoints: `mybucket.s3.amazonaws.com` and `mybucket.s3.eu-west-2.amazonaws.com`, respectively.

## Conclusion

That's a wrap for chapter six. We implemented the least connections algorithm and, if you haven't already, try to implement the weighted random load balancing algorithm on your own.

See you next time!
